---
title: "Outlier Detection for RS-Derived Surface Water Temperature Estimates Using A Variational Autoencoder Method"
author: "B. Steele"
date: today
date-format: long
editor: 
  visual:
    theme: sky
editor-options:
  markdown:
    wrap: 80
format: pdf
bilbliography:
  references.bib
bibliography: references.bib
---

[GH Repo](https://github.com/steeleb/ATS-ML-Fall2023)

```{r envSetup, echo=FALSE, message=FALSE}
library(tidyverse)
library(reticulate)
library(kableExtra)
library(Metrics)
library(ggpmisc)
library(ggthemes)

# activate conda env
use_condaenv('~/miniconda3/envs/env_ATSML/')

# data directory
dir = "/Users/steeleb/OneDrive - Colostate/NASA-Northern/data/NN_train_val_test/"
```

```{python importModules}
#| echo: false
#| message: false
#| include: false

import os
import sys
import imp
import numpy as np
import seaborn as sb
import pickle
import pandas as pd
import datetime
import tensorflow as tf
import sklearn
import matplotlib.pyplot as plt

# custom modules
this_dir = "/Users/steeleb/Documents/GitHub/ATS-ML-Fall2023/"
```

# Scientific Motivation and Problem Statement

![Remote sensing-enhanced lake surface temeperature record for the seven manually-monitored Northern Water waterbodies. Manually-measured surface temperature represented by black translucent dots, remote-sensing derived values are in gold translucent dots.](images/is_rs_surface_temp_v2023-11-28.png "Figure 1"){#fig-enhancedRecord width="500"}

We use the Landsat Collection 2 surface temperature (ST) product [@cook2014] to create a more robust dataset for our analyses, supplementing the manually-measured surface temeperature at lakes monitored by Northern Water (see @fig-enhancedRecord). The product performs particularly poorly when clouds are present or even near the area of interest - instances of this tend to result in lower-than-expected (or measured) temperature values, even though the associated metadata does not indicate that there are clouds near or at the location of interest. Additionally, the thermal sensor on the Landsat constellation has a native resolution of 100m, and we mask the data at 30m (the resolution of the optical sensors, where we determine water extent). Because the reservoirs we are interested in obtaining surface temperature for are dynamic, it is possible we are inadvertantly including land-contaminated pixels in the summary of the area of interest. Since the final goal of modeling daily surface temperature is to launch a real-time decision support system, it is imperative that we don't include contaminated data into our pipeline since these data are the foundational building blocks for other optically-derived parameter estimates we will be modeling.

In an attempt to identify outliers/novel data points from the remote sensing data, I will using a variational autoencoder (VAE) trained on the *in situ* temperature measurements and associated data to establish thresholds for outlier detection for the ST product at lakes where we have measured, *in situ* data. While this method is typically used on raster-type data in conjunction with convolutional neural networks, I'm hopeful that implementation could be similar on vector data since the input data, at some point in the VAE architecture are flattened to vector-like data.

The baseline for this implementation is the results of the previous neural network framework, where the daily model performance had an MAE of 1.8 and a RMSE of 2.2 degrees Celsius. If we feed only the remote sensing data which passes the variational autencoder threshold test and the MAE and RMSE decrease, we will consider this method to perform better than baseline.

# Description of the Data

```{r loadData, echo = F, message = F}
is_dir = '~/OneDrive - Colostate/NASA-Northern/data/waterQuality/harmonized/'
surf_temp <- read_csv(file.path(is_dir, 'manual_temperature_data_NW_harmonized_v2023-08-30.csv')) %>% 
  group_by(date, feature) %>% 
  arrange(depth) %>% 
  slice(1) %>% 
  filter(station %in% c('CL-DAM1', 'GR-DAM', 'GL-MID', 'HT-DIX', 
                        'SM-DAM', 'WC-DAM', 'WG-DAM')) %>%
  filter(date < ymd("2023-01-01"))

rs_dir = '~/OneDrive - Colostate/NASA-Northern/data/remoteSensing/estimates/'
NW_estimates <- read_csv(file.path(rs_dir, 'SurfTemp_linearCorrection_v2023-11-28.csv')) %>% 
  rename(feature = GNIS_Name) %>% 
  mutate(value = adj_medTemp,
         feature = case_when(feature == 'Lake Granby' ~ 'Granby Reservoir',
                             feature == 'Carter Lake Reservoir' ~ 'Carter Lake',
                             feature == 'Shadow Mountain Lake' ~ 'Shadow Mountain Reservoir',
                             TRUE ~ feature),
         station = 'sat') %>% 
  filter(location_type == 'poi_center')

NW_obs_est <- NW_estimates %>% filter(feature %in% unique(surf_temp$feature))

same_day <- NW_estimates %>% 
  rename(est_value = value) %>% 
  select(-station) %>% 
  inner_join(., surf_temp)

same_day_lm <- lm(same_day$est_value ~ same_day$value)

same_day$residuals <- resid(same_day_lm)

same_day_rmse <- round(rmse(same_day$value, same_day$est_value), 2)
same_day_mae <- round(mae(same_day$value, same_day$est_value), 2)

n_gt_mae <- same_day %>% 
  filter(residuals > same_day_mae) %>% 
  nrow()
```

Northern Water, the municipal subdistrict that delivers drinking water to approximately 1 million people in northern Colorado and irrigation water for \~600,000 acres of land has an exhaustive manual measurement record for many of the lakes within their network. The manual sampling record contains `r nrow(surf_temp)` surface temperature measurements from `r length(unique(surf_temp$feature))` lakes. 'Surface temperature' in the manual sampling record is defined as any measured temperature at ≤ 1m depth. I retain only the top-most value when multiple measurements were available. The data from Landsat 4-9's surface temperature product contains `r nrow(NW_obs_est)` observations for these same lakes. While these thermal estimates are well-aligned with the manual monitoring data and have been bias-corrected (RMSE `r same_day_rmse`ºC, MAE `r same_day_mae`ºC., Figure 2), there are still outliers when comparing these data with same-day measured surface temperature. Furthermore, these only represent `r nrow(same_day)` of the `r nrow(NW_obs_est)` remotely-sensed values within these seven reservoirs, and `r n_gt_mae` have residuals greater than the MAE for this subset.

```{r figSameDay, echo=FALSE, fig.cap="Preliminary calibrated Landsat-derived surface temperature where same-day *in situ* measurements available (n = 63). Note obvious outliers at Willow Creek Reservoir (dark blue, Carter Lake(black), Windy Gap Reservoir (red) that require further investigation into QA/QC before integration into decision support system pipeline."}
ggplot(same_day, aes(x = value, y = est_value)) + 
  geom_abline(slope = 1, intercept = 0, lty = 2, color = 'grey') +
  # geom_abline(slope = lm_loc_subset_adj$coefficients[2], intercept = lm_loc_subset_adj$coefficients[1], lty = 3, color = 'black') +
    stat_poly_eq(aes(label =  paste(after_stat(adj.rr.label))),
               formula = y~x, parse = TRUE,
               label.y = Inf, vjust = 1.3) +
  geom_point(aes(color = feature)) +
  coord_cartesian(xlim = c(0, 27),
                  ylim = c(0, 27)) +
  theme_bw() +
  labs(x = 'Manually-Measured Surface Temperature (°C)',
       y = 'Adjusted Remotely-Sensed\nSurface Temperature (°C)',
       title = 'Northern Water Waterbody/Remote Sensing\nPreliminary Temperature Product',
       subtitle = 'Grey dashed line is 1:1', 
       color = NULL) +
  theme(#legend.position = 'bottom', 
        plot.title = element_text(hjust = 0.5, face = 'bold'),
        plot.subtitle = element_text(hjust = 0.5)) +
  guides(color=guide_legend(ncol = 1, byrow=TRUE)) +
    scale_color_colorblind()
```

The features that I will be using to train and validate this VAE for outlier detection are surface temperature, summarized NLDAS meteorological data (air temperature, precipitation, solar radiation, and wind), and static values for each of the reservoirs (elevation, surface area, maximum depth, volume, and shoreline distance). The NLDAS data have been summarized for the previous day's weather, 3 days prior, and 5 days prior - meaning, the model does not use *today's* weather for prediction. To capture annual warming and seasonal warm-up/cool-down, which are not always consistent between annual cycles, I've implemented an annual cumulative sum for both temperature and solar radiation and the day of year within the feature set. Because static features are incomplete for Windy Gap Reservoir, data from that reservoir is not included in this analysis.

The training set will include all `r nrow(NW_obs_est)` measurements from the NW record in the six reservoirs with complete feature sets. These data are reliable and should adequately train the VAE to reconstruct the data from patterns in the latent space that are inherent to the feature set. The validation set to calculate a threshold for outliers will be the `r nrow(same_day)`, where instances where the residual is less than MAE are defined as *inliers* and those greater than MAE are *outliers*. An analysis of the reconstruction error will be used to define a threshold for *inliers* and *outliers* as described in @sinha2021.

## Data preprocessing

All NLDAS precipitation data are right skewed heavily biased to low precip values including zero, to account for this and make the distribution more normal, I added 0.0001 to each value and applied a log-10 transformation to this subset. The wind data were left skewed and to transform the distribution, I used a square root transformation. All features and labels were then scaled using the mean and standard deviation from the training dataset to get the values closer around zero, which are preferable for neural networks. This is the same preprocessing that was used in the neural networks assignment.

## Training-Validation-Test Splits

Fort the autoencoder implementation, I used a leave-one-out training/validation split, where each lake was iteratively left out of the model development, creating 6 models. The test data are those from 2021 forward.

For development of the threshold cutoff, I used the instances of same-day *in situ* measurements and remote sensing values shown in Figure 2. For training-validation, I'll use the same leave-one-out technique, and if the threshold is similar across training/validation datasets, I will unify the data and create a more robust threshold model with all data. There will be no 'test' set in this instance because of the small amount of data. Testing for this example would be through implementation of this VAE-defined threshold method.

# Autoencoder Setup

The set up of this VAE was very conservative, using two fully connected dense layers for both the encoder and decoder with three codings for the latent space. Batch size was set to 32. The dense layers for the encoder were comprised of 20 then 10 nodes, the decoder comprised of 10 then 20 nodes all with *relu* activation. Input and reconstruction (output) layers contained 33 nodes, one for each standardized variable value. Linear activation was used for the reconstruction layer. To reduce overfitting, I also added a dropout layer with a dropout rate of 20% between the input and first dense layer.

Loss function is for this VAE was the sum of the variational autoencoder's latent loss:

$$
\mathscr{L} = - \frac{1}2 \sum^n_{i=1}\biggr[1+log(\sigma_i^2)-\sigma_i^2-\mu_i^2\biggr]
$$

And reconstruction loss, which was mean squared error (MSE):

$$
MSE = \sum_{i=1}^{n}(x_i-\hat{x}_i)^2
$$

# Results

To determine if the model was performing as expected, I will examine the temperature values in the reconstruction for the test dataset. While the other parameters are important to the modeling effort, determining temperature outliers is the purpose of the implementation of the VAE. The reconstructed temperature values should be strongly linearly related to the input temperature values. Figure @fig-VAEtemp shows the resulting reconstructed, standardized temperature value (y) plotted against the actual standardized temperature value.

# ![](images/loo_models_basic-03.png)Conclusions {#fig-VAEtemp}

In hindsight, I think adding a weight to the reconstruction loss to add more weight divergence in temperature would have been particularily useful. Sadly, I've completely run out of time to make thoughtful conclusions! I am particularily interested to see how the VAE handles the outlier/inlier data and whether or not it does make a difference in the NN models. While I don't have time to add that here, I will send an update if/when I get to the point where I have actually gone through the entire application of the VAE for outlier detection.

# Citations
