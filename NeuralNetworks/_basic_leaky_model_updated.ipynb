{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script creates a leaky_basic overfit model for predicting surface temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/v7bmckc139v2dqcm04jgfjlr0000gn/T/ipykernel_21560/3752334599.py:4: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "#high level modules\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# ml/ai modules\n",
    "import tensorflow as tf\n",
    "# Let's import some different things we will use to build the neural network\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Softmax\n",
    "\n",
    "# import custom modules\n",
    "this_dir = \"/Users/steeleb/Documents/GitHub/ATS-ML-Fall2023/\"\n",
    "imp.load_source(\"settings\",os.path.join(this_dir,\"NeuralNetworks/settings.py\"))\n",
    "from settings import settings\n",
    "imp.load_source(\"tvt\", os.path.join(this_dir, \"02_preprocessing_updated.py\"))\n",
    "from tvt import train1, val1, train2, val2, train3, val3, train4, val4, train5, val5, train6, val6, train7, val7, train8, val8, train9, val9\n",
    "from tvt import train1_ts, val1_ts, train2_ts, val2_ts, train3_ts, val3_ts, train4_ts, val4_ts\n",
    "imp.load_source(\"architecture\", os.path.join(this_dir, \"NeuralNetworks/architecture.py\"))\n",
    "from architecture import build_model, compile_model\n",
    "imp.load_source(\"universals\", os.path.join(this_dir, \"universal_functions.py\"))\n",
    "from universals import save_to_pickle, get_features_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format training and validation arrays for use in model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features1, labels_1, val_features1, val_labels_1 = get_features_labels(train1, val1)\n",
    "features2, labels_2, val_features2, val_labels_2 = get_features_labels(train2, val2)\n",
    "features3, labels_3, val_features3, val_labels_3 = get_features_labels(train3, val3)\n",
    "features4, labels_4, val_features4, val_labels_4 = get_features_labels(train4, val4)\n",
    "features5, labels_5, val_features5, val_labels_5 = get_features_labels(train5, val5)\n",
    "features6, labels_6, val_features6, val_labels_6 = get_features_labels(train6, val6)\n",
    "features7, labels_7, val_features7, val_labels_7 = get_features_labels(train7, val7)\n",
    "features8, labels_8, val_features8, val_labels_8 = get_features_labels(train8, val8)\n",
    "features9, labels_9, val_features9, val_labels_9 = get_features_labels(train9, val9)\n",
    "\n",
    "ts_features1, ts_labels_1, ts_val_features1, ts_val_labels_1 = get_features_labels(train1_ts, val1_ts)\n",
    "ts_features2, ts_labels_2, ts_val_features2, ts_val_labels_2 = get_features_labels(train2_ts, val2_ts)\n",
    "ts_features3, ts_labels_3, ts_val_features3, ts_val_labels_3 = get_features_labels(train3_ts, val3_ts)\n",
    "ts_features4, ts_labels_4, ts_val_features4, ts_val_labels_4 = get_features_labels(train4_ts, val4_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 35)]              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 35)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                720       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,581\n",
      "Trainable params: 1,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 16:21:43.527954: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-18 16:21:43.528092: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-10-18 16:21:43.683278: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-10-18 16:21:43.832833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 8ms/step - loss: 0.7793 - val_loss: 0.4273\n",
      "Epoch 2/1000\n",
      "16/57 [=======>......................] - ETA: 0s - loss: 0.3173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 16:21:44.420688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2614 - val_loss: 0.3299\n",
      "Epoch 3/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2063 - val_loss: 0.2617\n",
      "Epoch 4/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1985 - val_loss: 0.2568\n",
      "Epoch 5/1000\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1959 - val_loss: 0.2559\n",
      "Epoch 6/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1920 - val_loss: 0.2587\n",
      "Epoch 7/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1910 - val_loss: 0.2599\n",
      "Epoch 8/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1894 - val_loss: 0.2357\n",
      "Epoch 9/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1874 - val_loss: 0.2380\n",
      "Epoch 10/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1853 - val_loss: 0.2249\n",
      "Epoch 11/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1843 - val_loss: 0.2395\n",
      "Epoch 12/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1799 - val_loss: 0.2372\n",
      "Epoch 13/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1835 - val_loss: 0.2270\n",
      "Epoch 14/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1796 - val_loss: 0.2316\n",
      "Epoch 15/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1791 - val_loss: 0.2236\n",
      "Epoch 16/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1744 - val_loss: 0.2129\n",
      "Epoch 17/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1793 - val_loss: 0.2142\n",
      "Epoch 18/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1739 - val_loss: 0.2054\n",
      "Epoch 19/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1742 - val_loss: 0.1985\n",
      "Epoch 20/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1696 - val_loss: 0.2179\n",
      "Epoch 21/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1752 - val_loss: 0.2002\n",
      "Epoch 22/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1703 - val_loss: 0.1967\n",
      "Epoch 23/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1710 - val_loss: 0.1994\n",
      "Epoch 24/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1703 - val_loss: 0.1984\n",
      "Epoch 25/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1686 - val_loss: 0.2221\n",
      "Epoch 26/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1690 - val_loss: 0.1869\n",
      "Epoch 27/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1701 - val_loss: 0.1850\n",
      "Epoch 28/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1680 - val_loss: 0.1887\n",
      "Epoch 29/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1680 - val_loss: 0.1955\n",
      "Epoch 30/1000\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1677 - val_loss: 0.1898\n",
      "Epoch 31/1000\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1663 - val_loss: 0.1841\n",
      "Epoch 32/1000\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1687 - val_loss: 0.1828\n",
      "Epoch 33/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1678 - val_loss: 0.1970\n",
      "Epoch 34/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1678 - val_loss: 0.1936\n",
      "Epoch 35/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1641 - val_loss: 0.1903\n",
      "Epoch 36/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1683 - val_loss: 0.2076\n",
      "Epoch 37/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1641 - val_loss: 0.2014\n",
      "Epoch 38/1000\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1641 - val_loss: 0.1962\n",
      "Epoch 39/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1658 - val_loss: 0.1884\n",
      "Epoch 40/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1654 - val_loss: 0.2043\n",
      "Epoch 41/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1654 - val_loss: 0.1864\n",
      "Epoch 42/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1663 - val_loss: 0.1907\n",
      "Epoch 43/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1640 - val_loss: 0.1953\n",
      "Epoch 44/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1905\n",
      "Epoch 45/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1629 - val_loss: 0.2004\n",
      "Epoch 46/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1781\n",
      "Epoch 47/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1649 - val_loss: 0.2202\n",
      "Epoch 48/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1636 - val_loss: 0.2029\n",
      "Epoch 49/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1621 - val_loss: 0.1953\n",
      "Epoch 50/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1975\n",
      "Epoch 51/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1592 - val_loss: 0.1962\n",
      "Epoch 52/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1659 - val_loss: 0.1823\n",
      "Epoch 53/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1629 - val_loss: 0.2080\n",
      "Epoch 54/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.2142\n",
      "Epoch 55/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1965\n",
      "Epoch 56/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1583 - val_loss: 0.1923\n",
      "Epoch 57/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.2136\n",
      "Epoch 58/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1585 - val_loss: 0.2041\n",
      "Epoch 59/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1588 - val_loss: 0.1922\n",
      "Epoch 60/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1584 - val_loss: 0.1895\n",
      "Epoch 61/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1636 - val_loss: 0.2143\n",
      "Epoch 62/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1579 - val_loss: 0.2072\n",
      "Epoch 63/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.2207\n",
      "Epoch 64/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.2189\n",
      "Epoch 65/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1586 - val_loss: 0.2106\n",
      "Epoch 66/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1581 - val_loss: 0.2042\n",
      "Epoch 67/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1562 - val_loss: 0.2097\n",
      "Epoch 68/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1556 - val_loss: 0.2046\n",
      "Epoch 69/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1584 - val_loss: 0.1997\n",
      "Epoch 70/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1575 - val_loss: 0.2062\n",
      "Epoch 71/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1586 - val_loss: 0.1839\n",
      "Epoch 72/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1578 - val_loss: 0.2233\n",
      "Epoch 73/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1567 - val_loss: 0.1969\n",
      "Epoch 74/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1554 - val_loss: 0.2003\n",
      "Epoch 75/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1570 - val_loss: 0.2171\n",
      "Epoch 76/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1533 - val_loss: 0.1909\n",
      "Epoch 77/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1538 - val_loss: 0.2048\n",
      "Epoch 78/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1532 - val_loss: 0.2120\n",
      "Epoch 79/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1590 - val_loss: 0.2462\n",
      "Epoch 80/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1581 - val_loss: 0.2150\n",
      "Epoch 81/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1560 - val_loss: 0.2250\n",
      "Epoch 82/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1575 - val_loss: 0.2133\n",
      "Epoch 83/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1565 - val_loss: 0.2003\n",
      "Epoch 84/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1586 - val_loss: 0.1985\n",
      "Epoch 85/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1548 - val_loss: 0.2055\n",
      "Epoch 86/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1549 - val_loss: 0.2046\n",
      "Epoch 87/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1564 - val_loss: 0.2117\n",
      "Epoch 88/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1566 - val_loss: 0.2121\n",
      "Epoch 89/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1586 - val_loss: 0.2026\n",
      "Epoch 90/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1548 - val_loss: 0.2010\n",
      "Epoch 91/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1506 - val_loss: 0.2192\n",
      "Epoch 92/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1545 - val_loss: 0.2223\n",
      "Epoch 93/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1510 - val_loss: 0.1913\n",
      "Epoch 94/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1510 - val_loss: 0.2058\n",
      "Epoch 95/1000\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1516 - val_loss: 0.1912\n",
      "Epoch 96/1000\n",
      "33/57 [================>.............] - ETA: 0s - loss: 0.1561"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(settings[\"leaky_basic\"][\"random_seed\"])\n",
    "\n",
    "# define the early stopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "  monitor=\"val_loss\", \n",
    "  patience=settings[\"leaky_basic\"][\"patience\"], \n",
    "  restore_best_weights=True, \n",
    "  mode=\"auto\"\n",
    ")\n",
    "\n",
    "## LOO 1\n",
    "model_1 = build_model(\n",
    "  features1, \n",
    "  labels_1, \n",
    "  settings[\"leaky_basic\"])\n",
    "\n",
    "model_1 = compile_model(\n",
    "  model_1, \n",
    "  settings['leaky_basic'])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_1 = model_1.fit(\n",
    "  features1, \n",
    "  labels_1, \n",
    "  epochs=settings['leaky_basic'][\"max_epochs\"],\n",
    "  batch_size=settings['leaky_basic'][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features1, val_labels_1],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## LOO 2\n",
    "model_2 = build_model(\n",
    "  features2,\n",
    "  labels_2, \n",
    "  settings[\"leaky_basic\"])\n",
    "model_2 = compile_model(model_2, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_2 = model_2.fit(\n",
    "  features2,\n",
    "  labels_2,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features2, val_labels_2],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## LOO 3\n",
    "\n",
    "model_3 = build_model(\n",
    "  features3,\n",
    "  labels_3,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_3 = compile_model(model_3, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_3 = model_3.fit(\n",
    "  features3,\n",
    "  labels_3,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features3, val_labels_3],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## LOO 4\n",
    "\n",
    "model_4 = build_model(\n",
    "  features4,\n",
    "  labels_4,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_4 = compile_model(model_4, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_4 = model_4.fit(\n",
    "  features4,\n",
    "  labels_4,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features4, val_labels_4],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## LOO 5\n",
    "\n",
    "model_5 = build_model(\n",
    "  features5,\n",
    "  labels_5,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_5 = compile_model(model_5, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_5 = model_5.fit(\n",
    "  features5,\n",
    "  labels_5,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features5, val_labels_5],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## LOO 6\n",
    "\n",
    "model_6 = build_model(\n",
    "  features6,\n",
    "  labels_6,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_6 = compile_model(model_6, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_6 = model_6.fit(\n",
    "  features6,\n",
    "  labels_6,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features6, val_labels_6],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "## LOO 7\n",
    "\n",
    "model_7 = build_model(\n",
    "  features7,\n",
    "  labels_7,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_7 = compile_model(model_7, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_7 = model_7.fit(\n",
    "  features7,\n",
    "  labels_7,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features7, val_labels_7],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## LOO 8\n",
    "\n",
    "model_8 = build_model(\n",
    "  features8,\n",
    "  labels_8,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_8 = compile_model(model_8, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_8 = model_8.fit(\n",
    "  features8,\n",
    "  labels_8,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features8, val_labels_8],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "## LOO 9\n",
    "\n",
    "model_9 = build_model(\n",
    "  features9,\n",
    "  labels_9,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_9 = compile_model(model_9, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_9 = model_9.fit(\n",
    "  features9,\n",
    "  labels_9,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[val_features9, val_labels_9],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the models and training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dir = \"/Users/steeleb/OneDrive - Colostate/NASA-Northern/data/NN_train_val_test/regional_daily_temp/models/leaky_basic_updated/\"\n",
    "\n",
    "# save models to pickle\n",
    "models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9]\n",
    "\n",
    "for model, i in zip(models, range(1,10)):\n",
    "    save_to_pickle(model, f\"{dump_dir}/model_{i}.pkl\")\n",
    "\n",
    "# save history to pickles\n",
    "histories = [history_1, history_2, history_3, history_4, history_5, history_6, history_7, history_8, history_9]\n",
    "\n",
    "for history, i in zip(histories, range(1,10)):\n",
    "    save_to_pickle(history, f\"{dump_dir}/history_{i}.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then do the same for timeseries train/val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(settings[\"leaky_basic\"][\"random_seed\"])\n",
    "\n",
    "# define the early stopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "  monitor=\"val_loss\", \n",
    "  patience=settings[\"leaky_basic\"][\"patience\"], \n",
    "  restore_best_weights=True, \n",
    "  mode=\"auto\"\n",
    ")\n",
    "\n",
    "## TS 1\n",
    "model_1_ts = build_model(\n",
    "  ts_features1, \n",
    "  ts_labels_1, \n",
    "  settings[\"leaky_basic\"])\n",
    "\n",
    "model_1_ts = compile_model(\n",
    "  model_1_ts, \n",
    "  settings['leaky_basic'])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_1_ts = model_1_ts.fit(\n",
    "  ts_features1, \n",
    "  ts_labels_1, \n",
    "  epochs=settings['leaky_basic'][\"max_epochs\"],\n",
    "  batch_size=settings['leaky_basic'][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[ts_val_features1, ts_val_labels_1],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## TS 2\n",
    "model_2_ts = build_model(\n",
    "  ts_features2,\n",
    "  ts_labels_2, \n",
    "  settings[\"leaky_basic\"])\n",
    "model_2_ts = compile_model(model_2_ts, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_2_ts = model_2_ts.fit(\n",
    "  ts_features2,\n",
    "  ts_labels_2,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[ts_val_features2, ts_val_labels_2],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## TS 3\n",
    "\n",
    "model_3_ts = build_model(\n",
    "  ts_features3,\n",
    "  ts_labels_3,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_3_ts = compile_model(model_3_ts, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_3_ts = model_3_ts.fit(\n",
    "  ts_features3,\n",
    "  ts_labels_3,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[ts_val_features3, ts_val_labels_3],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "## TS 4\n",
    "\n",
    "model_4_ts = build_model(\n",
    "  ts_features4,\n",
    "  ts_labels_4,\n",
    "  settings[\"leaky_basic\"])\n",
    "model_4_ts = compile_model(model_4_ts, settings[\"leaky_basic\"])\n",
    "\n",
    "# train the model via model.fit\n",
    "history_4_ts = model_4_ts.fit(\n",
    "  ts_features4,\n",
    "  ts_labels_4,\n",
    "  epochs=settings[\"leaky_basic\"][\"max_epochs\"],\n",
    "  batch_size=settings[\"leaky_basic\"][\"batch_size\"],\n",
    "  shuffle=True,\n",
    "  validation_data=[ts_val_features4, ts_val_labels_4],\n",
    "  callbacks=[early_stopping_callback],\n",
    "  verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save to pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models to pickle\n",
    "ts_models = [model_1_ts, model_2_ts, model_3_ts, model_4_ts]\n",
    "\n",
    "for model, i in zip(ts_models, range(1,5)):\n",
    "    save_to_pickle(model, f\"{dump_dir}/ts_model_{i}.pkl\")\n",
    "\n",
    "# save history to pickles\n",
    "ts_histories = [history_1_ts, history_2_ts, history_3_ts, history_4_ts]\n",
    "\n",
    "for history, i in zip(ts_histories, range(1,5)):\n",
    "    save_to_pickle(history, f\"{dump_dir}/ts_history_{i}.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
