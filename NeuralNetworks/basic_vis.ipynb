{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick visualizations of the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high level modules\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# ml/ai modules\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# custom modules\n",
    "this_dir = \"/Users/steeleb/Documents/GitHub/ATS-ML-Fall2023/\"\n",
    "imp.load_source(\"tvt\", os.path.join(this_dir, \"NeuralNetworks/preprocessing.py\"))\n",
    "from tvt import training\n",
    "from tvt import train1, val1, train2, val2, train3, val3, train4, val4, train5, val5, train6, val6\n",
    "from tvt import train1_ts, val1_ts, train2_ts, val2_ts, train3_ts, val3_ts, train4_ts, val4_ts\n",
    "imp.load_source(\"universals\", os.path.join(this_dir, \"NeuralNetworks/universal_functions.py\"))\n",
    "from universals import load_pickle_file, get_features_labels, predict_values, print_error_metrics\n",
    "imp.load_source(\"vis\", os.path.join(this_dir, \"NeuralNetworks/vis_functions.py\"))\n",
    "from vis import create_scatter_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in models from pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model directory path\n",
    "model_dir = '/Users/steeleb/OneDrive - Colostate/NASA-Northern/data/NN_train_val_test/models/basic/'\n",
    "\n",
    "histories = [f for f in os.listdir(model_dir) if 'history' in f]\n",
    "\n",
    "ts_models = [f for f in histories if 'ts' in f]\n",
    "ts_histories.sort()\n",
    "\n",
    "histories = [f for f in histories if 'ts' not in f]\n",
    "histories.sort()\n",
    "\n",
    "ts_history_1 = load_pickle_file(ts_histories[0], model_dir)\n",
    "ts_history_2 = load_pickle_file(ts_histories[1], model_dir)\n",
    "ts_history_3 = load_pickle_file(ts_histories[2], model_dir)\n",
    "ts_history_4 = load_pickle_file(ts_histories[3], model_dir)\n",
    "\n",
    "history_1 = load_pickle_file(histories[0], model_dir)\n",
    "history_2 = load_pickle_file(histories[1], model_dir)\n",
    "history_3 = load_pickle_file(histories[2], model_dir)\n",
    "history_4 = load_pickle_file(histories[3], model_dir)\n",
    "history_5 = load_pickle_file(histories[4], model_dir)\n",
    "history_6 = load_pickle_file(histories[5], model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll look at the training and validation loss and accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_1.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_1.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig1.suptitle(\"LOO dataset 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_2.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_2.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig2.suptitle(\"LOO dataset 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_3.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_3.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig3.suptitle(\"LOO dataset 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_4.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_4.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig4.suptitle(\"LOO dataset 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_5.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_5.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_5.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_5.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig5.suptitle(\"LOO dataset 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_6.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_6.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_6.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_6.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig6.suptitle(\"LOO dataset 6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_1.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_1.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig1ts.suptitle(\"TS dataset 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_2.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_2.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig2ts.suptitle(\"TS dataset 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_3.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_3.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig3ts.suptitle(\"TS dataset 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_4.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_4.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig4ts.suptitle(\"TS dataset 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data, models and look at actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1, labels_1, val_features1, val_labels_1 = get_features_labels(train1, val1)\n",
    "features2, labels_2, val_features2, val_labels_2 = get_features_labels(train2, val2)\n",
    "features3, labels_3, val_features3, val_labels_3 = get_features_labels(train3, val3)\n",
    "features4, labels_4, val_features4, val_labels_4 = get_features_labels(train4, val4)\n",
    "features5, labels_5, val_features5, val_labels_5 = get_features_labels(train5, val5)\n",
    "features6, labels_6, val_features6, val_labels_6 = get_features_labels(train6, val6)\n",
    "\n",
    "ts_features1, ts_labels_1, ts_val_features1, ts_val_labels_1 = get_features_labels(train1_ts, val1_ts)\n",
    "ts_features2, ts_labels_2, ts_val_features2, ts_val_labels_2 = get_features_labels(train2_ts, val2_ts)\n",
    "ts_features3, ts_labels_3, ts_val_features3, ts_val_labels_3 = get_features_labels(train3_ts, val3_ts)\n",
    "ts_features4, ts_labels_4, ts_val_features4, ts_val_labels_4 = get_features_labels(train4_ts, val4_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [f for f in os.listdir(model_dir) if 'history' not in f]\n",
    "\n",
    "ts_models = [f for f in models if 'ts' in f]\n",
    "ts_models.sort()\n",
    "\n",
    "models = [f for f in models if 'ts' not in f]\n",
    "models.sort()\n",
    "\n",
    "ts_model_1 = load_pickle_file(ts_models[0])\n",
    "ts_model_2 = load_pickle_file(ts_models[1])\n",
    "ts_model_3 = load_pickle_file(ts_models[2])\n",
    "ts_model_4 = load_pickle_file(ts_models[3])\n",
    "\n",
    "model_1 = load_pickle_file(models[0])\n",
    "model_2 = load_pickle_file(models[1])\n",
    "model_3 = load_pickle_file(models[2])\n",
    "model_4 = load_pickle_file(models[3])\n",
    "model_5 = load_pickle_file(models[4])\n",
    "model_6 = load_pickle_file(models[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vals(transformed_val, mean, std):\n",
    "  actual_val = (transformed_val * std) + mean\n",
    "  return actual_val\n",
    "\n",
    "transform = pd.read_csv('/Users/steeleb/OneDrive - Colostate/NASA-Northern/data/NN_train_val_test/mean_std_training_v2023-11-09.csv')\n",
    "transform.set_index(transform.columns[0], inplace=True)\n",
    "\n",
    "t_mean = transform.loc['value']['mean']\n",
    "t_std = transform.loc['value']['std']\n",
    "\n",
    "pred_1 = model_1.predict(features1)\n",
    "val_1 = model_1.predict(val_features1)\n",
    "p_act_1 = calculate_vals(pred_1, t_mean, t_std)\n",
    "l_act_1 = calculate_vals(labels_1, t_mean, t_std)\n",
    "v_act_1 = calculate_vals(val_1, t_mean, t_std)\n",
    "l_v_act_1 = calculate_vals(val_labels_1, t_mean, t_std)\n",
    "\n",
    "pred_2 = model_2.predict(features2)\n",
    "val_2 = model_2.predict(val_features2)\n",
    "p_act_2 = calculate_vals(pred_2, t_mean, t_std)\n",
    "v_act_2 = calculate_vals(val_2, t_mean, t_std)\n",
    "\n",
    "pred_3 = model_3.predict(features3)\n",
    "val_3 = model_3.predict(val_features3)\n",
    "p_act_3 = calculate_vals(pred_3, t_mean, t_std)\n",
    "v_act_3 = calculate_vals(val_3, t_mean, t_std)\n",
    "\n",
    "pred_4 = model_4.predict(features4)\n",
    "val_4 = model_4.predict(val_features4)\n",
    "p_act_4 = calculate_vals(pred_4, t_mean, t_std)\n",
    "v_act_4 = calculate_vals(val_4, t_mean, t_std)\n",
    "\n",
    "pred_5 = model_5.predict(features5)\n",
    "val_5 = model_5.predict(val_features5)\n",
    "p_act_5 = calculate_vals(pred_5, t_mean, t_std)\n",
    "v_act_5 = calculate_vals(val_5, t_mean, t_std)\n",
    "\n",
    "pred_6 = model_6.predict(features6)\n",
    "val_6 = model_6.predict(val_features6)\n",
    "p_act_6 = calculate_vals(pred_6, t_mean, t_std)\n",
    "v_act_6 = calculate_vals(val_6, t_mean, t_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pred_1 = ts_model_1.predict(features1_ts)\n",
    "ts_val_1 = ts_model_1.predict(val_features1_ts)\n",
    "ts_p_act_1 = calculate_vals(ts_pred_1, t_mean, t_std)\n",
    "ts_v_act_1 = calculate_vals(ts_val_1, t_mean, t_std)\n",
    "\n",
    "ts_pred_2 = ts_model_2.predict(features2_ts)\n",
    "ts_val_2 = ts_model_2.predict(val_features2_ts)\n",
    "ts_p_act_2 = calculate_vals(ts_pred_2, t_mean, t_std)\n",
    "ts_v_act_2 = calculate_vals(ts_val_2, t_mean, t_std)\n",
    "\n",
    "ts_pred_3 = ts_model_3.predict(features3_ts)\n",
    "ts_val_3 = ts_model_3.predict(val_features3_ts)\n",
    "ts_p_act_3 = calculate_vals(ts_pred_3, t_mean, t_std)\n",
    "ts_v_act_3 = calculate_vals(ts_val_3, t_mean, t_std)\n",
    "\n",
    "ts_pred_4 = ts_model_4.predict(features4_ts)\n",
    "ts_val_4 = ts_model_4.predict(val_features4_ts)\n",
    "ts_p_act_4 = calculate_vals(ts_pred_4, t_mean, t_std)\n",
    "ts_v_act_4 = calculate_vals(ts_val_4, t_mean, t_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot for dataset 1\n",
    "plt.scatter(v_act_1, l_v_act_1, color='blue', label='Validation')\n",
    "plt.scatter(p_act_1, l_act_1, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 2\n",
    "plt.scatter(v_act_2, val_labels_2, color='blue', label='Validation')\n",
    "plt.scatter(p_act_2, labels_2, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 3\n",
    "plt.scatter(v_act_3, val_labels_3, color='blue', label='Validation')\n",
    "plt.scatter(p_act_3, labels_3, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 4\n",
    "plt.scatter(v_act_4, val_labels_4, color='blue', label='Validation')\n",
    "plt.scatter(p_act_4, labels_4, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 4')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 5\n",
    "plt.scatter(v_act_5, val_labels_5, color='blue', label='Validation')\n",
    "plt.scatter(p_act_5, labels_5, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 5')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 6\n",
    "plt.scatter(v_act_6, val_labels_6, color='blue', label='Validation')\n",
    "plt.scatter(p_act_6, labels_6, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 6')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 1\n",
    "plt.scatter(ts_v_act_1, val_labels_1_ts, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_1, labels_1_ts, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 2\n",
    "plt.scatter(ts_v_act_2, val_labels_2_ts, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_2, labels_2_ts, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 3\n",
    "plt.scatter(ts_v_act_3, val_labels_3_ts, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_3, labels_3_ts, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 4\n",
    "plt.scatter(ts_v_act_4, val_labels_4_ts, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_4, labels_4_ts, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 4')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate mean squared error for dataset 1\n",
    "t_mse_1 = mean_squared_error(l_act_1, p_act_1)\n",
    "t_mae_1 = mean_absolute_error(l_act_1, p_act_1)\n",
    "v_mse_1 = mean_squared_error(l_v_act_1, v_act_1)\n",
    "v_mae_1 = mean_absolute_error(l_v_act_1, v_act_1)\n",
    "print(\"Mean Squared Error for Training Dataset 1:\", t_mse_1)\n",
    "print(\"Mean Absolute Error for Training Dataset 1:\", t_mae_1)\n",
    "\n",
    "print(\"Mean Squared Error for Validation Dataset 1:\", v_mse_1)\n",
    "print(\"Mean Absolute Error for Validation Dataset 1:\", v_mae_1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ATSML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
