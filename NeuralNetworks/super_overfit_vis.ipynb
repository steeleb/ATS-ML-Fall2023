{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick visualizations of the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high level modules\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# ml/ai modules\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# custom modules\n",
    "this_dir = \"/Users/steeleb/Documents/GitHub/ATS-ML-Fall2023/\"\n",
    "imp.load_source(\"tvt\", os.path.join(this_dir, \"NeuralNetworks/preprocessing.py\"))\n",
    "from tvt import training\n",
    "from tvt import train1, val1, train2, val2, train3, val3, train4, val4, train5, val5, train6, val6\n",
    "from tvt import train1_ts, val1_ts, train2_ts, val2_ts, train3_ts, val3_ts, train4_ts, val4_ts\n",
    "\n",
    "# model directory path\n",
    "model_dir = '/Users/steeleb/OneDrive - Colostate/NASA-Northern/data/NN_train_val_test/models/super_overfit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in models from pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file(file_name):\n",
    "    \"\"\"\n",
    "    Load a pickle file from a given file path and file name.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the directory containing the pickle file.\n",
    "    file_name (str): The name of the pickle file.\n",
    "\n",
    "    Returns:\n",
    "    any: The object stored in the pickle file.\n",
    "    \"\"\"\n",
    "    with open(model_dir + '/' + file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = [f for f in os.listdir(model_dir) if 'history' in f]\n",
    "\n",
    "ts_histories = [f for f in histories if 'ts' in f]\n",
    "ts_histories.sort()\n",
    "\n",
    "histories = [f for f in histories if 'ts' not in f]\n",
    "histories.sort()\n",
    "\n",
    "ts_history_1 = load_pickle_file(ts_histories[0])\n",
    "ts_history_2 = load_pickle_file(ts_histories[1])\n",
    "ts_history_3 = load_pickle_file(ts_histories[2])\n",
    "ts_history_4 = load_pickle_file(ts_histories[3])\n",
    "\n",
    "history_1 = load_pickle_file(histories[0])\n",
    "history_2 = load_pickle_file(histories[1])\n",
    "history_3 = load_pickle_file(histories[2])\n",
    "history_4 = load_pickle_file(histories[3])\n",
    "history_5 = load_pickle_file(histories[4])\n",
    "history_6 = load_pickle_file(histories[5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll look at the training and validation loss and accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_1.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_1.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig1.suptitle(\"LOO dataset 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_2.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_2.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig2.suptitle(\"LOO dataset 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_3.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_3.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig3.suptitle(\"LOO dataset 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_4.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_4.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig4.suptitle(\"LOO dataset 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_5.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_5.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_5.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_5.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig5.suptitle(\"LOO dataset 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(history_6.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(history_6.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history_6.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(history_6.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig6.suptitle(\"LOO dataset 6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_1.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_1.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_1.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig1ts.suptitle(\"TS dataset 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_2.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_2.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_2.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig2ts.suptitle(\"TS dataset 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_3.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_3.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_3.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig3ts.suptitle(\"TS dataset 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4ts, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(ts_history_4.history[\"loss\"], label=\"training\")\n",
    "axs[0].plot(ts_history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ts_history_4.history[\"loss\"], label=\"training\")\n",
    "axs[1].plot(ts_history_4.history[\"val_loss\"], label=\"validation\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig4ts.suptitle(\"TS dataset 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data, models and look at actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the values we want to predict\n",
    "labels_1 = np.array(train1['value'])\n",
    "labels_2 = np.array(train2['value'])\n",
    "labels_3 = np.array(train3['value'])\n",
    "labels_4 = np.array(train4['value'])\n",
    "labels_5 = np.array(train5['value'])\n",
    "labels_6 = np.array(train6['value'])\n",
    "\n",
    "# grab the values we want to predict\n",
    "val_labels_1 = np.array(val1['value'])\n",
    "val_labels_2 = np.array(val2['value'])\n",
    "val_labels_3 = np.array(val3['value'])\n",
    "val_labels_4 = np.array(val4['value'])\n",
    "val_labels_5 = np.array(val5['value'])\n",
    "val_labels_6 = np.array(val6['value'])\n",
    "\n",
    "# and remove the labels from the dataset containing the feature set\n",
    "features1 = (train1\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features2 = (train2\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features3 = (train3\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features4 = (train4\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features5 = (train5\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features6 = (train6\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "\n",
    "# and remove the labels from the dataset containing the feature set\n",
    "val_features1 = (val1\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features2 = (val2\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features3 = (val3\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features4 = (val4\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features5 = (val5\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features6 = (val6\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features1.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features1 = np.array(features1)\n",
    "features2 = np.array(features2)\n",
    "features3 = np.array(features3)\n",
    "features4 = np.array(features4)\n",
    "features5 = np.array(features5)\n",
    "features6 = np.array(features6)\n",
    "\n",
    "# Convert to numpy array\n",
    "val_features1 = np.array(val_features1)\n",
    "val_features2 = np.array(val_features2)\n",
    "val_features3 = np.array(val_features3)\n",
    "val_features4 = np.array(val_features4)\n",
    "val_features5 = np.array(val_features5)\n",
    "val_features6 = np.array(val_features6)\n",
    "\n",
    "\n",
    "# grab the values we want to predict\n",
    "labels_1_ts = np.array(train1_ts['value'])\n",
    "labels_2_ts = np.array(train2_ts['value'])\n",
    "labels_3_ts = np.array(train3_ts['value'])\n",
    "labels_4_ts = np.array(train4_ts['value'])\n",
    "\n",
    "# grab the values we want to predict\n",
    "val_labels_1_ts = np.array(val1_ts['value'])\n",
    "val_labels_2_ts = np.array(val2_ts['value'])\n",
    "val_labels_3_ts = np.array(val3_ts['value'])\n",
    "val_labels_4_ts = np.array(val4_ts['value'])\n",
    "\n",
    "# and remove the labels from the dataset containing the feature set\n",
    "features1_ts = (train1_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features2_ts = (train2_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features3_ts = (train3_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "features4_ts = (train4_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "\n",
    "# and remove the labels from the dataset containing the feature set\n",
    "val_features1_ts = (val1_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features2_ts = (val2_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features3_ts = (val3_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "val_features4_ts = (val4_ts\n",
    "  .drop(['value', 'feature', 'date'], axis = 1))\n",
    "\n",
    "# Convert to numpy array\n",
    "features1_ts = np.array(features1_ts)\n",
    "features2_ts = np.array(features2_ts)\n",
    "features3_ts = np.array(features3_ts)\n",
    "features4_ts = np.array(features4_ts)\n",
    "\n",
    "# Convert to numpy array\n",
    "val_features1_ts = np.array(val_features1_ts)\n",
    "val_features2_ts = np.array(val_features2_ts)\n",
    "val_features3_ts = np.array(val_features3_ts)\n",
    "val_features4_ts = np.array(val_features4_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [f for f in os.listdir(model_dir) if 'history' not in f]\n",
    "\n",
    "ts_models = [f for f in models if 'ts' in f]\n",
    "ts_models.sort()\n",
    "\n",
    "models = [f for f in models if 'ts' not in f]\n",
    "models.sort()\n",
    "\n",
    "ts_model_1 = load_pickle_file(ts_models[0])\n",
    "ts_model_2 = load_pickle_file(ts_models[1])\n",
    "ts_model_3 = load_pickle_file(ts_models[2])\n",
    "ts_model_4 = load_pickle_file(ts_models[3])\n",
    "\n",
    "model_1 = load_pickle_file(models[0])\n",
    "model_2 = load_pickle_file(models[1])\n",
    "model_3 = load_pickle_file(models[2])\n",
    "model_4 = load_pickle_file(models[3])\n",
    "model_5 = load_pickle_file(models[4])\n",
    "model_6 = load_pickle_file(models[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vals(transformed_val, mean, std):\n",
    "  actual_val = (transformed_val * std) + mean\n",
    "  return actual_val\n",
    "\n",
    "transform = pd.read_csv('/Users/steeleb/OneDrive - Colostate/NASA-Northern/data/NN_train_val_test/mean_std_training_v2023-11-09.csv')\n",
    "transform.set_index(transform.columns[0], inplace=True)\n",
    "\n",
    "t_mean = transform.loc['value']['mean']\n",
    "t_std = transform.loc['value']['std']\n",
    "\n",
    "pred_1 = model_1.predict(features1)\n",
    "val_1 = model_1.predict(val_features1)\n",
    "p_act_1 = calculate_vals(pred_1, t_mean, t_std)\n",
    "l_act_1 = calculate_vals(labels_1, t_mean, t_std)\n",
    "v_act_1 = calculate_vals(val_1, t_mean, t_std)\n",
    "l_v_act_1 = calculate_vals(val_labels_1, t_mean, t_std)\n",
    "\n",
    "pred_2 = model_2.predict(features2)\n",
    "val_2 = model_2.predict(val_features2)\n",
    "p_act_2 = calculate_vals(pred_2, t_mean, t_std)\n",
    "l_act_2 = calculate_vals(labels_2, t_mean, t_std)\n",
    "v_act_2 = calculate_vals(val_2, t_mean, t_std)\n",
    "l_v_act_2 = calculate_vals(val_labels_2, t_mean, t_std)\n",
    "\n",
    "pred_3 = model_3.predict(features3)\n",
    "val_3 = model_3.predict(val_features3)\n",
    "p_act_3 = calculate_vals(pred_3, t_mean, t_std)\n",
    "l_act_3 = calculate_vals(labels_3, t_mean, t_std)\n",
    "v_act_3 = calculate_vals(val_3, t_mean, t_std)\n",
    "l_v_act_3 = calculate_vals(val_labels_3, t_mean, t_std)\n",
    "\n",
    "pred_4 = model_4.predict(features4)\n",
    "val_4 = model_4.predict(val_features4)\n",
    "p_act_4 = calculate_vals(pred_4, t_mean, t_std)\n",
    "l_act_4 = calculate_vals(labels_4, t_mean, t_std)\n",
    "v_act_4 = calculate_vals(val_4, t_mean, t_std)\n",
    "l_v_act_4 = calculate_vals(val_labels_4, t_mean, t_std)\n",
    "\n",
    "pred_5 = model_5.predict(features5)\n",
    "val_5 = model_5.predict(val_features5)\n",
    "p_act_5 = calculate_vals(pred_5, t_mean, t_std)\n",
    "l_act_5 = calculate_vals(labels_5, t_mean, t_std)\n",
    "v_act_5 = calculate_vals(val_5, t_mean, t_std)\n",
    "l_v_act_5 = calculate_vals(val_labels_5, t_mean, t_std)\n",
    "\n",
    "pred_6 = model_6.predict(features6)\n",
    "val_6 = model_6.predict(val_features6)\n",
    "p_act_6 = calculate_vals(pred_6, t_mean, t_std)\n",
    "l_act_6 = calculate_vals(labels_6, t_mean, t_std)\n",
    "v_act_6 = calculate_vals(val_6, t_mean, t_std)\n",
    "l_v_act_6 = calculate_vals(val_labels_6, t_mean, t_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pred_1 = ts_model_1.predict(features1_ts)\n",
    "ts_val_1 = ts_model_1.predict(val_features1_ts)\n",
    "ts_p_act_1 = calculate_vals(ts_pred_1, t_mean, t_std)\n",
    "ts_l_act_1 = calculate_vals(labels_1_ts, t_mean, t_std)\n",
    "ts_v_act_1 = calculate_vals(ts_val_1, t_mean, t_std)\n",
    "ts_l_v_act_1 = calculate_vals(val_labels_1_ts, t_mean, t_std)\n",
    "\n",
    "ts_pred_2 = ts_model_2.predict(features2_ts)\n",
    "ts_val_2 = ts_model_2.predict(val_features2_ts)\n",
    "ts_p_act_2 = calculate_vals(ts_pred_2, t_mean, t_std)\n",
    "ts_l_act_2 = calculate_vals(labels_2_ts, t_mean, t_std)\n",
    "ts_v_act_2 = calculate_vals(ts_val_2, t_mean, t_std)\n",
    "ts_l_v_act_2 = calculate_vals(val_labels_2_ts, t_mean, t_std)\n",
    "\n",
    "ts_pred_3 = ts_model_3.predict(features3_ts)\n",
    "ts_val_3 = ts_model_3.predict(val_features3_ts)\n",
    "ts_p_act_3 = calculate_vals(ts_pred_3, t_mean, t_std)\n",
    "ts_l_act_3 = calculate_vals(labels_3_ts, t_mean, t_std)\n",
    "ts_v_act_3 = calculate_vals(ts_val_3, t_mean, t_std)\n",
    "ts_l_v_act_3 = calculate_vals(val_labels_3_ts, t_mean, t_std)\n",
    "\n",
    "ts_pred_4 = ts_model_4.predict(features4_ts)\n",
    "ts_val_4 = ts_model_4.predict(val_features4_ts)\n",
    "ts_p_act_4 = calculate_vals(ts_pred_4, t_mean, t_std)\n",
    "ts_l_act_4 = calculate_vals(labels_4_ts, t_mean, t_std)\n",
    "ts_v_act_4 = calculate_vals(ts_val_4, t_mean, t_std)\n",
    "ts_l_v_act_4 = calculate_vals(val_labels_4_ts, t_mean, t_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot for dataset 1\n",
    "plt.scatter(v_act_1, l_v_act_1, color='blue', label='Validation')\n",
    "plt.scatter(p_act_1, l_act_1, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 2\n",
    "plt.scatter(v_act_2, l_v_act_2, color='blue', label='Validation')\n",
    "plt.scatter(p_act_2, l_act_2, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 3\n",
    "plt.scatter(v_act_3, l_v_act_3, color='blue', label='Validation')\n",
    "plt.scatter(p_act_3, l_act_3, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 4\n",
    "plt.scatter(v_act_4, l_v_act_4, color='blue', label='Validation')\n",
    "plt.scatter(p_act_4, l_act_4, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 4')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 5\n",
    "plt.scatter(v_act_5, l_v_act_5, color='blue', label='Validation')\n",
    "plt.scatter(p_act_5, l_act_5, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 5')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for dataset 6\n",
    "plt.scatter(v_act_6, l_v_act_6, color='blue', label='Validation')\n",
    "plt.scatter(p_act_6, l_act_6, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Dataset 6')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 1\n",
    "plt.scatter(ts_v_act_1, ts_l_v_act_1, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_1, ts_l_act_1, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 2\n",
    "plt.scatter(ts_v_act_2, ts_l_v_act_2, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_2, ts_l_act_2, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 3\n",
    "plt.scatter(ts_v_act_3, ts_l_v_act_3, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_3, ts_l_act_3, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create scatter plot for time series dataset 4\n",
    "plt.scatter(ts_v_act_4, ts_l_v_act_4, color='blue', label='Validation')\n",
    "plt.scatter(ts_p_act_4, ts_l_act_4, color='red', label='Training')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.title('Time Series Dataset 4')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate error metrics for dataset 1\n",
    "t_mse_1 = mean_squared_error(l_act_1, p_act_1)\n",
    "t_mae_1 = mean_absolute_error(l_act_1, p_act_1)\n",
    "v_mse_1 = mean_squared_error(l_v_act_1, v_act_1)\n",
    "v_mae_1 = mean_absolute_error(l_v_act_1, v_act_1)\n",
    "print(\"Mean Squared Error for Training Dataset 1:\", t_mse_1)\n",
    "print(\"Mean Absolute Error for Training Dataset 1:\", t_mae_1)\n",
    "print(\"Mean Squared Error for Validation Dataset 1:\", v_mse_1)\n",
    "print(\"Mean Absolute Error for Validation Dataset 1:\", v_mae_1)\n",
    "\n",
    "# calculate error metrics for dataset 2\n",
    "t_mse_2 = mean_squared_error(l_act_2, p_act_2)\n",
    "t_mae_2 = mean_absolute_error(l_act_2, p_act_2)\n",
    "v_mse_2 = mean_squared_error(l_v_act_2, v_act_2)\n",
    "v_mae_2 = mean_absolute_error(l_v_act_2, v_act_2)\n",
    "print(\"Mean Squared Error for Training Dataset 2:\", t_mse_2)\n",
    "print(\"Mean Absolute Error for Training Dataset 2:\", t_mae_2)\n",
    "print(\"Mean Squared Error for Validation Dataset 2:\", v_mse_2)\n",
    "print(\"Mean Absolute Error for Validation Dataset 2:\", v_mae_2)\n",
    "\n",
    "# calculate error metrics for dataset 3\n",
    "t_mse_3 = mean_squared_error(l_act_3, p_act_3)\n",
    "t_mae_3 = mean_absolute_error(l_act_3, p_act_3)\n",
    "v_mse_3 = mean_squared_error(l_v_act_3, v_act_3)\n",
    "v_mae_3 = mean_absolute_error(l_v_act_3, v_act_3)\n",
    "print(\"Mean Squared Error for Training Dataset 3:\", t_mse_3)\n",
    "print(\"Mean Absolute Error for Training Dataset 3:\", t_mae_3)\n",
    "print(\"Mean Squared Error for Validation Dataset 3:\", v_mse_3)\n",
    "print(\"Mean Absolute Error for Validation Dataset 3:\", v_mae_3)\n",
    "\n",
    "# calculate error metrics for dataset 4\n",
    "t_mse_4 = mean_squared_error(l_act_4, p_act_4)\n",
    "t_mae_4 = mean_absolute_error(l_act_4, p_act_4)\n",
    "v_mse_4 = mean_squared_error(l_v_act_4, v_act_4)\n",
    "v_mae_4 = mean_absolute_error(l_v_act_4, v_act_4)\n",
    "print(\"Mean Squared Error for Training Dataset 4:\", t_mse_4)\n",
    "print(\"Mean Absolute Error for Training Dataset 4:\", t_mae_4)\n",
    "print(\"Mean Squared Error for Validation Dataset 4:\", v_mse_4)\n",
    "print(\"Mean Absolute Error for Validation Dataset 4:\", v_mae_4)\n",
    "\n",
    "# calculate error metrics for dataset 5\n",
    "t_mse_5 = mean_squared_error(l_act_5, p_act_5)\n",
    "t_mae_5 = mean_absolute_error(l_act_5, p_act_5)\n",
    "v_mse_5 = mean_squared_error(l_v_act_5, v_act_5)\n",
    "v_mae_5 = mean_absolute_error(l_v_act_5, v_act_5)\n",
    "print(\"Mean Squared Error for Training Dataset 5:\", t_mse_5)\n",
    "print(\"Mean Absolute Error for Training Dataset 5:\", t_mae_5)\n",
    "print(\"Mean Squared Error for Validation Dataset 5:\", v_mse_5)\n",
    "print(\"Mean Absolute Error for Validation Dataset 5:\", v_mae_5)\n",
    "\n",
    "# calculate error metrics for dataset 6\n",
    "t_mse_6 = mean_squared_error(l_act_6, p_act_6)\n",
    "t_mae_6 = mean_absolute_error(l_act_6, p_act_6)\n",
    "v_mse_6 = mean_squared_error(l_v_act_6, v_act_6)\n",
    "v_mae_6 = mean_absolute_error(l_v_act_6, v_act_6)\n",
    "print(\"Mean Squared Error for Training Dataset 6:\", t_mse_6)\n",
    "print(\"Mean Absolute Error for Training Dataset 6:\", t_mae_6)\n",
    "print(\"Mean Squared Error for Validation Dataset 6:\", v_mse_6)\n",
    "print(\"Mean Absolute Error for Validation Dataset 6:\", v_mae_6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ATSML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
