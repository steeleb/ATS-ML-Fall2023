---
title: "Estimation of Daily Water Temperature using Random Forest"
author: "B Steele"
date: today
date-format: long
format: pdf
editor: 
  visual:
    theme: sky
---

```{r env-set-up, echo=FALSE, message=FALSE}
library(tidyverse)
library(reticulate)
library(kableExtra)

# read in temp data
NW_temp <- read_csv('~/OneDrive - Colostate/NASA-Northern/data/waterQuality/harmonized/manual_temperature_data_NW_harmonized_v2023-08-30.csv')
surf_temp <- NW_temp %>% 
  group_by(date, feature) %>% 
  arrange(depth) %>% 
  slice(1) %>% 
  filter(station %in% c('CL-DAM1', 'GR-DAM', 'GL-MID', 'HT-DIX', 
                        'SM-DAM', 'WC-DAM', 'WG-DAM'))
  
NW_estimates <- read_csv('~/OneDrive - Colostate/NASA-Northern/data/remoteSensing/NW_lake_LandsatC2_ST_v2023-05-31.csv') %>% 
  select(date, GNIS_Name, Permanent_Identifier, med_SurfaceTemp) %>% 
  rename(feature = GNIS_Name) %>% 
  mutate(value = med_SurfaceTemp - 273.15,
         feature = case_when(feature == 'Lake Granby' ~ 'Granby Reservoir',
                             feature == 'Carter Lake Reservoir' ~ 'Carter Lake',
                             TRUE ~ feature),
         station = 'sat')

all_NW_temp <- full_join(surf_temp, NW_estimates)

# weather data
weather <- read_csv('~/OneDrive - Colostate/NASA-Northern/data/climate/aggregated/NW_NLDAS_climate_1-3-5d_previous_1984-01-01_2023-05-17_v2023-05-25.csv') %>% 
  rename(feature = lake) %>% 
  pivot_longer(cols = c('tot_precip_mm', 'max_temp_degC', 'mean_temp_degC', 
                        'min_temp_degC', 'tot_sol_rad_Wpm2', 'min_wind_mps',
                        'mean_wind_mps', 'max_wind_mps'),
               names_to = 'variable') %>% 
  pivot_wider(names_from = c('variable', 'n_prev_days'),
              names_sep = '_',
              values_from = 'value') %>% 
  mutate(feature = if_else(feature == 'Lake Granby',
                           'Granby Reservoir',
                           feature))

# static
static <- read_csv('~/OneDrive - Colostate/NASA-Northern/data/static_vars/static_vars_7_lakes.csv')

# join together for full dataset
full_dataset = left_join(all_NW_temp, weather) %>% 
  left_join(., static) %>% 
  select(-c(Permanent_Identifier, med_SurfaceTemp, depth))

# activate conda env
use_condaenv('~/miniconda3/envs/env_ATSML/')

```

## Checkpoint Issues:

-   is this a defensible way to do train/val/test? Should I leave an additional lake out for validation?
-   how do I establish a baseline for this? better than yesterday-is-today? (when I don't have a daily timeseries, can I do this?)
-   

## Scientific motivation and problem statement:

Water temperature is often a reliable indicator of general water quality (cite). Active monitoring of lakes, especially those that are difficult to access by monitoring personnel, is difficult. Additionally, manual monitoring of waterbodies (by physically visiting a site) and sensor networks to monitor water temperature, are costly endeavors (cite).

In this example, I will use Random Forest to estimate water surface temperature for reservoirs with long manual monitoring data from Northern Water. The features that I will be using to estimate surface temperature include summary NLDAS meteorological data (air temperature, precipitation, solar radiation, and wind) as well as static values for each of the reservoirs (elevation, surface area, maximum depth, volume, and shoreline distance).

In addition to the manual sampling record that is maintained by Northern water, I will be leveraging surface temperature estimates from the Landsat constellation, Landsat 4-9. These thermal estimates are well-aligned with the manual monitoring data for the 7 reservoirs. 'Surface temperature' in the manual sampling record for this example is any measured temperature at \>= 1m depth. I retain only the top-most value for temperature. Static variables are only available for 6 of 7 reservoirs, so Windy Gap reservoir has been dropped from this analysis.

\[\[add units to table\]\]

```{r static-vars-table, echo = F}
static %>% 
  kbl(format = 'markdown', 
      caption = 'Static variables used in the Random Forest algorithm. Windy Gap
Reservoir has incomplete data and has been dropped from this analysis.')

all_NW_temp <- all_NW_temp %>% 
  filter(feature != 'Windy Gap Reservoir')
```

Ideally, implementation of this algorithm will include application to lakes that have only Landsat-derived temperature estimates and that are outside of this dataset. Because I want this algorithm to perform well on new lakes, I want to take steps to make sure that it is not overfit to these specific lakes.

## Training/Validation/Testing

It's clear that there are site-level differences in temperature range and general seasonal response (fig?). These differences are likely due to static variables that differentiate these lakes. That said, if I add in site-level information, the algorithm will quickly learn those key attributes and likely overfit to the data, not allowing for generalization beyond these lakes.

Due to this, my test set will be comprised of data from a lake that was never used in the train/validate set (Carter Lake).

For validation, I'll be using timeseries-aware cross validation, leaving 5-year periods of data out to validate on. The workflow I use for cross validation is an adaptation of [this script](https://github.com/eabarnes1010/course_ml_ats/blob/main/code/rf_regress_christman.ipynb).

```{python, import-modules}
#| echo: false
import sys
import numpy as np
import matplotlib.pyplot as plt

import pandas as pd
import datetime
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import export_graphviz
from sklearn.inspection import permutation_importance
import pydot
import matplotlib.pyplot as plt
```

## Write up contents:

-   description of any data pre-processing performed and why you did it

-   machine learning setup and reasons for hyperparameter choices when relevant

-   results (e.g. testing accuracy)

-   a detailed discussion of why you don't think you have overfit

-   a detailed discussion of why you think the results are better (or worse if that is the case) than a baseline approach of your choice (e.g. random chance, linear regression, climatology, etc)

-   concluding thoughts including any insights gained from your efforts
